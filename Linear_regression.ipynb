{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "Linear Regression is a *supervised learning* algorithm used for **regression tasks**.\n",
    "\n",
    "The model assumes a **linear relationship** between the features (independent variables) and the target variable (dependent variable). The relationship is typically expressed as:\n",
    "\n",
    "$$\n",
    "y = \\beta_{0} + \\beta_{1}x_{1} + ... + \\beta_{n}x_{n} + \\epsilon\n",
    "$$\n",
    "\n",
    "Here:\n",
    "\n",
    "* $y$ is the target variable (output).\n",
    "* $x_{1}, ..., x_{n}$ are the features (inputs).\n",
    "* $\\beta_{0}, \\beta_{1}, ..., \\beta_{n}$ are the coefficients of the features.\n",
    "* $\\epsilon$ is the error term, accounting for the variation not captured by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is fitted to the training data, which means finding the values of the coefficients $\\beta_{0}, \\beta_{1}, ..., \\beta_{n}$ that minimize the error (typically using methods like Ordinary Least Squares, which minimizes the sum of the squared differences or *residuals* between the observed values and the values predicted by the model).\n",
    "\n",
    "Once the coefficients are calculated, they can be used to predict 'new' target values ($\\hat{y}$) by plugging in the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications\n",
    "\n",
    "Linear regression is one of the simplest models used for *predicting modeling* like forecasting. But it can also be used for *statistical inference* (where the goal is to determine the relationship's strenght and direction between the features and the target). Another application is the study of *feature significance*, in other words determine which feature or features changes impact more the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions\n",
    "\n",
    "\n",
    "*   Linearity: The relationship between the predictors and the outcome is linear. This hypothesis can be tested before hand with visualization techniques or statistical tools to name a few.\n",
    "\n",
    "*   Independence of Errors: The residuals (errors) should be independent of each other. If the errors are correlated the model might underestimate or overestimate the significance of predictors, leading to incorrect conclusions or predictions.\n",
    "\n",
    "*   Homoscedasticity: The variance of residuals should be constant across all levels of the independent variables. A simple way to check for this is to plot the residulas against the predicted values. If the spread of residuals looks like a random cloud (no pattern), the data is likely homoscedastic. If the spread widens or narrows as predicted values increase (e.g., a cone shape), then the data is heteroscedastic\n",
    "\n",
    "*   Normality of Errors: Residuals should be normally distributed\n",
    "\n",
    "*   No Multicollinearity (in multiple regression): Predictors should not be highly correlated with each other. \n",
    "\n",
    "*   No Outliers: Extreme values in the data can disproportionately affect the model fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
